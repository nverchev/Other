{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chamfer distance for Pytorch: comparison",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nverchev/other_Python_projects/blob/main/Chamfer_distance_for_Pytorch_comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is the best implementation of the Chamfer Distance?\n",
        "\n",
        "We compare a simple implementation with other two coming from two libraries.\n",
        "- https://github.com/otaheri/chamfer_distance\n",
        "- https://pypi.org/project/chamferdist/1.0.0/#description\n",
        "\n",
        "These implementatations are compatible with torch.autograd, and we test them using GPU power.\n",
        "\n",
        "I suggest to run the experiment different times to account for some possible overhead."
      ],
      "metadata": {
        "id": "_x5EAhMS0xKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#First implementation \n",
        "!pip install git+'https://github.com/otaheri/chamfer_distance'\n",
        "\n",
        "#Second implementation\n",
        "!pip install chamferdist\n"
      ],
      "metadata": {
        "id": "zFeIlNYZ17ZP",
        "outputId": "41fbff20-3aac-4aa3-8257-8de4566c2670",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/otaheri/chamfer_distance\n",
            "  Cloning https://github.com/otaheri/chamfer_distance to /tmp/pip-req-build-339r55yu\n",
            "  Running command git clone -q https://github.com/otaheri/chamfer_distance /tmp/pip-req-build-339r55yu\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from chamfer-distance==0.1) (1.11.0+cu113)\n",
            "Collecting Ninja\n",
            "  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 5.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1.0->chamfer-distance==0.1) (4.2.0)\n",
            "Building wheels for collected packages: chamfer-distance\n",
            "  Building wheel for chamfer-distance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chamfer-distance: filename=chamfer_distance-0.1-py3-none-any.whl size=5653 sha256=bc2fd7cf40db8d70b9ed35bded402d47689e6bd608b4b15d8b6b23a05f6c1744\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gz8keqk8/wheels/2a/c5/7c/395771526a57f81590f5b9e2be57f219f834d894e10b1cd993\n",
            "Successfully built chamfer-distance\n",
            "Installing collected packages: Ninja, chamfer-distance\n",
            "Successfully installed Ninja-1.10.2.3 chamfer-distance-0.1\n",
            "Collecting chamferdist\n",
            "  Downloading chamferdist-1.0.0.tar.gz (16 kB)\n",
            "Building wheels for collected packages: chamferdist\n",
            "  Building wheel for chamferdist (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chamferdist: filename=chamferdist-1.0.0-cp37-cp37m-linux_x86_64.whl size=5836539 sha256=75262b5ebc6eaf550ac4c973b50649f2c22466133013c26fbd9389553f9caa71\n",
            "  Stored in directory: /root/.cache/pip/wheels/28/bb/d1/c789ecd6835e466e813f6e2c5e23bb1bbb2248e84586ba82d2\n",
            "Successfully built chamferdist\n",
            "Installing collected packages: chamferdist\n",
            "Successfully installed chamferdist-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "U6oFrClH0f-Y"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "pc1 = torch.rand([100,1000,3]).to()\n",
        "pc2 = torch.rand([100,100,3]).to()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from chamfer_distance import ChamferDistance\n",
        "chamdist = ChamferDistance()\n",
        "start = torch.cuda.Event(enable_timing=True)\n",
        "end = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "start.record()\n",
        "d1,d2,_,_ = chamdist(pc1,pc2) # dist forward, dist reverse\n",
        "d = d1.sum(axis=1).mean() + d2.sum(axis=1).mean() # batchmean\n",
        "end.record()\n",
        "torch.cuda.synchronize()\n",
        "\n",
        "print(\"First implementation:\")\n",
        "print(\"Time (ms): \", start.elapsed_time(end))\n",
        "print(\"Result: \", d)"
      ],
      "metadata": {
        "id": "aRiecm8Y2KrY",
        "outputId": "68ffa9bc-ad08-48d4-df2d-03ae24c2c18a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First implementation:\n",
            "Time (ms):  205.4356231689453\n",
            "Result:  tensor(19.5597)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from chamferdist import ChamferDistance\n",
        "chamdist = ChamferDistance()\n",
        "start = torch.cuda.Event(enable_timing=True)\n",
        "end = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "start.record()\n",
        "d = chamdist(pc1,pc2, bidirectional=True, reduction=\"mean\") \n",
        "end.record()\n",
        "torch.cuda.synchronize()\n",
        "\n",
        "print(\"Second implementation:\")\n",
        "print(\"Time (ms): \", start.elapsed_time(end))\n",
        "print(\"Result: \", d)"
      ],
      "metadata": {
        "id": "Kx7D1AOO2LE7",
        "outputId": "d5e9130d-6ca8-4c9e-cb40-31889d36e976",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Second implementation:\n",
            "Time (ms):  198.42588806152344\n",
            "Result:  tensor(19.5597)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def square_distance(t1, t2):\n",
        "    t2 = t2.permute(0, 2, 1)\n",
        "    dist = -2 * torch.matmul(t1, t2)\n",
        "    dist += torch.sum(t1 ** 2, 2, keepdim=True)\n",
        "    dist += torch.sum(t2 ** 2, 1, keepdim=True)\n",
        "    return dist\n",
        "    \n",
        "# Chamfer Distance\n",
        "def chamdist(t1, t2): \n",
        "    dist = square_distance(t1, t2)\n",
        "    # forward + reverse\n",
        "    return torch.min(dist, axis = 2)[0].mean(0).sum()\\\n",
        "         + torch.min(dist, axis = 1)[0].mean(0).sum()\n",
        "\n",
        "start = torch.cuda.Event(enable_timing=True)\n",
        "end = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "start.record()\n",
        "d = chamdist(pc1, pc2)\n",
        "end.record()\n",
        "torch.cuda.synchronize()\n",
        "\n",
        "print(\"Simple implementation:\")\n",
        "print(\"Time: \", start.elapsed_time(end))\n",
        "print(\"Result: \", d)"
      ],
      "metadata": {
        "id": "7JA3VF7x2LoF",
        "outputId": "b2c7aa7e-f0d4-4867-a301-ea685fe03f62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simple implementation:\n",
            "Time:  72.68150329589844\n",
            "Result:  tensor(19.5597)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discussion\n",
        "Surprisingly, the simple implementation in torch is quicker than the ones from the two libraries.\n",
        "\n",
        "Hope this could be useful to anybody starting with PCD.\n"
      ],
      "metadata": {
        "id": "SP0qTMfE3wcG"
      }
    }
  ]
}